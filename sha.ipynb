{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMc2cACZCU2O9qhFNzziKac",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tusharraja/PP/blob/main/sha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phk225KUJ8In"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25e470c6"
      },
      "source": [
        "with open('test_file.txt', 'w') as f:\n",
        "    f.write('This is a test file for checksum calculation.')\n",
        "    f.write('It contains some arbitrary data....')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d826ca8",
        "outputId": "f065675a-9c65-4fcf-b9e6-d00dce1590fa"
      },
      "source": [
        "import hashlib\n",
        "\n",
        "def calculate_md5(filepath):\n",
        "    hasher = hashlib.md5()\n",
        "    with open(filepath, 'rb') as f:\n",
        "        while True:\n",
        "            chunk = f.read(4096)\n",
        "            if not chunk:\n",
        "                break\n",
        "            hasher.update(chunk)\n",
        "    return hasher.hexdigest()\n",
        "\n",
        "def calculate_sha512(filepath):\n",
        "    hasher = hashlib.sha512()\n",
        "    with open(filepath, 'rb') as f:\n",
        "        while True:\n",
        "            chunk = f.read(4096)\n",
        "            if not chunk:\n",
        "                break\n",
        "            hasher.update(chunk)\n",
        "    return hasher.hexdigest()\n",
        "\n",
        "filename = 'test_file.txt'\n",
        "\n",
        "md5_checksum = calculate_md5(filename)\n",
        "sha512_checksum = calculate_sha512(filename)\n",
        "\n",
        "print(f\"MD5 Checksum of {filename}: {md5_checksum}\")\n",
        "print(f\"SHA512 Checksum of {filename}: {sha512_checksum}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MD5 Checksum of test_file.txt: ad092983500636912dc8552192400fea\n",
            "SHA512 Checksum of test_file.txt: 84f223a5628442f145e661e5ea6b6ebb6f610d60507eb7ffa1bd40f6f85112f6d6ad22c2295d68f811646327cc78fc30a246ca9d0193b91cd88101c9fc2463f4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t4UdXXewKqh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11ebe664",
        "outputId": "2e72e832-0c9c-40de-b19c-4e7db3de493a"
      },
      "source": [
        "import hashlib\n",
        "\n",
        "def calculate_sha512(filepath):\n",
        "    hasher = hashlib.sha512()\n",
        "    with open(filepath, 'rb') as f:\n",
        "        while True:\n",
        "            chunk = f.read(4096)\n",
        "            if not chunk:\n",
        "                break\n",
        "            hasher.update(chunk)\n",
        "    return hasher.hexdigest()\n",
        "\n",
        "filename = 'test_file.txt'\n",
        "known_good_sha512 = 'b29c4bbd1ba91f384929bae47a9516dcb5782daa7c83feab2e6ccfc88b4718acaf2b8b09374762ba8aea0f40eac4f9cd5dc40e1b7b472911db8bb8ca47a36832'\n",
        "\n",
        "current_sha512 = calculate_sha512(filename)\n",
        "\n",
        "if current_sha512 == known_good_sha512:\n",
        "    print(f\"The file '{filename}' has not been tampered with. SHA512: {current_sha512}\")\n",
        "else:\n",
        "    print(f\"WARNING: The file '{filename}' may have been tampered with!\")\n",
        "    print(f\"Known good SHA512: {known_good_sha512}\")\n",
        "    print(f\"Current SHA512:    {current_sha512}\")\n",
        "\n",
        "\n",
        "with open('sha512_checksum.txt', 'w') as f:\n",
        "    f.write(current_sha512)\n",
        "print(f\"Current SHA512 checksum saved to sha512_checksum.txt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: The file 'test_file.txt' may have been tampered with!\n",
            "Known good SHA512: b29c4bbd1ba91f384929bae47a9516dcb5782daa7c83feab2e6ccfc88b4718acaf2b8b09374762ba8aea0f40eac4f9cd5dc40e1b7b472911db8bb8ca47a36832\n",
            "Current SHA512:    84f223a5628442f145e661e5ea6b6ebb6f610d60507eb7ffa1bd40f6f85112f6d6ad22c2295d68f811646327cc78fc30a246ca9d0193b91cd88101c9fc2463f4\n",
            "Current SHA512 checksum saved to sha512_checksum.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "989432d1",
        "outputId": "900b9281-4e89-4fd8-f040-e882c0accc21"
      },
      "source": [
        "import hashlib\n",
        "\n",
        "def calculate_sha512(filepath):\n",
        "    hasher = hashlib.sha512()\n",
        "    with open(filepath, 'rb') as f:\n",
        "        while True:\n",
        "            chunk = f.read(4096)\n",
        "            if not chunk:\n",
        "                break\n",
        "            hasher.update(chunk)\n",
        "    return hasher.hexdigest()\n",
        "\n",
        "filename = 'test_file.txt'\n",
        "current_sha512 = calculate_sha512(filename)\n",
        "\n",
        "output_filename = 'checksum.sha'\n",
        "with open(output_filename, 'w') as f:\n",
        "    f.write(current_sha512)\n",
        "print(f\"SHA512 checksum saved to {output_filename}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SHA512 checksum saved to checksum.sha\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4924f558",
        "outputId": "f3b55fe9-56cc-4355-c44d-702977a07d5d"
      },
      "source": [
        "with open('checksum.sha', 'r') as f:\n",
        "    content = f.read()\n",
        "print(f\"Content of checksum.sha:\\n{content}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Content of checksum.sha:\n",
            "84f223a5628442f145e661e5ea6b6ebb6f610d60507eb7ffa1bd40f6f85112f6d6ad22c2295d68f811646327cc78fc30a246ca9d0193b91cd88101c9fc2463f4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "def compute_file_hash(filepath, hash_algorithm='sha256'):\n",
        "\n",
        "    hash_algorithms = {\n",
        "        'md5': hashlib.md5(),\n",
        "        'sha1': hashlib.sha1(),\n",
        "        'sha256': hashlib.sha256(),\n",
        "        'sha512': hashlib.sha512()\n",
        "    }\n",
        "\n",
        "    if hash_algorithm.lower() not in hash_algorithms:\n",
        "        raise ValueError(f\"Unsupported hash algorithm: {hash_algorithm}\")\n",
        "\n",
        "    hash_obj = hash_algorithms[hash_algorithm.lower()]\n",
        "\n",
        "    try:\n",
        "        with open(filepath, 'rb') as file:\n",
        "            chunk_size = 8192  # 8KB\n",
        "            while chunk := file.read(chunk_size):\n",
        "                hash_obj.update(chunk)\n",
        "\n",
        "        return hash_obj.hexdigest()\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"File not found: {filepath}\")\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Error computing hash: {e}\")\n",
        "\n",
        "def generate_all_hashes(filepath):\n",
        "\n",
        "    algorithms = ['md5', 'sha1', 'sha256', 'sha512']\n",
        "    hashes = {}\n",
        "\n",
        "    for algorithm in algorithms:\n",
        "        try:\n",
        "            hashes[algorithm.upper()] = compute_file_hash(filepath, algorithm)\n",
        "        except Exception as e:\n",
        "            hashes[algorithm.upper()] = f\"Error: {e}\"\n",
        "\n",
        "    return hashes\n",
        "\n",
        "def create_hash_report(filepath, report_filename='hash_report.txt'):\n",
        "\n",
        "    try:\n",
        "        file_size = os.path.getsize(filepath)\n",
        "        filename = os.path.basename(filepath)\n",
        "        current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "        hashes = generate_all_hashes(filepath)\n",
        "\n",
        "        with open(report_filename, 'w') as report_file:\n",
        "\n",
        "            report_file.write(\"FILE HASH INTEGRITY REPORT\\n\")\n",
        "\n",
        "            report_file.write(f\"Filename: {filename}\\n\")\n",
        "            report_file.write(f\"Filepath: {filepath}\\n\")\n",
        "            report_file.write(f\"File Size: {file_size} bytes\\n\")\n",
        "            report_file.write(f\"Report Generated: {current_time}\\n\\n\")\n",
        "\n",
        "            report_file.write(\"HASH VALUES:\\n\")\n",
        "\n",
        "\n",
        "            for algorithm, hash_value in hashes.items():\n",
        "                report_file.write(f\"{algorithm:>8}: {hash_value}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "        print(f\"Hash report generated: {report_filename}\")\n",
        "        return hashes\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating hash report: {e}\")\n",
        "        return None\n",
        "\n",
        "def create_checksum_file(filepath, hash_algorithm='sha256'):\n",
        "\n",
        "    try:\n",
        "        hash_value = compute_file_hash(filepath, hash_algorithm)\n",
        "        filename = os.path.basename(filepath)\n",
        "        checksum_filename = f\"{filepath}.{hash_algorithm.lower()}\"\n",
        "\n",
        "        with open(checksum_filename, 'w') as checksum_file:\n",
        "            checksum_file.write(f\"{hash_value}  {filename}\\n\")\n",
        "\n",
        "        print(f\"Checksum file created: {checksum_filename}\")\n",
        "        return checksum_filename\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating checksum file: {e}\")\n",
        "        return None\n",
        "\n",
        "def create_all_checksum_files(filepath):\n",
        "\n",
        "    algorithms = ['md5', 'sha1', 'sha256', 'sha512']\n",
        "    checksum_files = {}\n",
        "\n",
        "    print(f\"Creating checksum files for: {filepath}\")\n",
        "\n",
        "    for algorithm in algorithms:\n",
        "        checksum_file = create_checksum_file(filepath, algorithm)\n",
        "        if checksum_file:\n",
        "            checksum_files[algorithm.upper()] = checksum_file\n",
        "\n",
        "    return checksum_files\n",
        "\n",
        "def verify_checksum(checksum_filepath):\n",
        "\n",
        "    try:\n",
        "        algorithm = checksum_filepath.split('.')[-1].lower()\n",
        "        if algorithm not in ['md5', 'sha1', 'sha256', 'sha512']:\n",
        "            return False, \"Unknown hash algorithm in checksum file\"\n",
        "\n",
        "        with open(checksum_filepath, 'r') as checksum_file:\n",
        "            line = checksum_file.read().strip()\n",
        "            parts = line.split('  ')\n",
        "\n",
        "            if len(parts) != 2:\n",
        "                return False, \"Invalid checksum file format\"\n",
        "\n",
        "            stored_hash = parts[0].strip()\n",
        "            original_filename = parts[1].strip()\n",
        "\n",
        "        checksum_dir = os.path.dirname(checksum_filepath)\n",
        "        if checksum_dir == '':\n",
        "            checksum_dir = '.'\n",
        "        original_filepath = os.path.join(checksum_dir, original_filename)\n",
        "\n",
        "        if not os.path.exists(original_filepath):\n",
        "            return False, f\"Original file not found: {original_filename}\"\n",
        "\n",
        "        current_hash = compute_file_hash(original_filepath, algorithm)\n",
        "\n",
        "        if stored_hash.lower() == current_hash.lower():\n",
        "            return True, f\"Checksum OK (Authentic) - {algorithm.upper()}\"\n",
        "        else:\n",
        "            return False, f\"Checksum FAILED (Tampered) - {algorithm.upper()}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return False, f\"Error during verification: {e}\"\n",
        "\n",
        "def verify_file_integrity(filepath, verbose=True):\n",
        "\n",
        "    algorithms = ['md5', 'sha1', 'sha256', 'sha512']\n",
        "    results = {}\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\nVerifying integrity of: {filepath}\")\n",
        "\n",
        "\n",
        "    for algorithm in algorithms:\n",
        "        checksum_file = f\"{filepath}.{algorithm}\"\n",
        "\n",
        "        if os.path.exists(checksum_file):\n",
        "            is_valid, message = verify_checksum(checksum_file)\n",
        "            results[algorithm.upper()] = {\n",
        "                'valid': is_valid,\n",
        "                'message': message,\n",
        "                'checksum_file': checksum_file\n",
        "            }\n",
        "\n",
        "            if verbose:\n",
        "                status = \"yes\" if is_valid else \"no\"\n",
        "                print(f\"{status} {algorithm.upper()}: {message}\")\n",
        "        else:\n",
        "            if verbose:\n",
        "                print(f\"? {algorithm.upper()}: No checksum file found ({checksum_file})\")\n",
        "\n",
        "    return results\n",
        "\n",
        "def display_verification_summary(results):\n",
        "\n",
        "    if not results:\n",
        "        print(\"\\nNo verification results to display.\")\n",
        "        return\n",
        "\n",
        "    valid_count = sum(1 for result in results.values() if result['valid'])\n",
        "    total_count = len(results)\n",
        "\n",
        "    print(f\"\\nVerification Summary:\")\n",
        "    print(f\"Valid checksums: {valid_count}/{total_count}\")\n",
        "\n",
        "    if valid_count == total_count:\n",
        "        print(\" FILE INTEGRITY VERIFIED: All checksums match.\")\n",
        "    elif valid_count == 0:\n",
        "        print(\" TAMPERING DETECTED: All checksums failed.\")\n",
        "    else:\n",
        "        print(f\" PARTIAL INTEGRITY: {valid_count} out of {total_count} checksums valid.\")\n",
        "\n",
        "def run_experiment():\n",
        "\n",
        "\n",
        "    print(\"HASH FUNCTION FILE INTEGRITY VERIFICATION EXPERIMENT\")\n",
        "\n",
        "\n",
        "\n",
        "    test_file = \"test_file.txt\"\n",
        "    test_content = \"\"\"Gukesh Dommaraju is an Indian chess grandmaster and the reigning World Chess Champion. A chess prodigy, Gukesh is the youngest undisputed world champion, the youngest player to have surpassed a FIDE rating of 2750, doing so at the age of 17, and the third-youngest to have surpassed 2700 Elo at the age of 16. Wikipedia\n",
        "Born: 29 May 2006 (age 19 years), Chennai\n",
        "Education: Velammal Vidyalaya Ayanambakkam\n",
        "FIDE rating: 2752 (October 2025)\n",
        "Peak ranking: No. 3 (March 2025)\n",
        "Peak rating: 2794 (October 2024)\n",
        "Title: Grandmaster (2019)\n",
        "World Champion: 2024â€“present\n",
        "\"\"\"\n",
        "\n",
        "    with open(test_file, 'w') as f:\n",
        "        f.write(test_content)\n",
        "\n",
        "    print(f\"\\n Test file created\")\n",
        "    print(f\"   File: {test_file}\")\n",
        "    print(f\"   Size: {os.path.getsize(test_file)} bytes\")\n",
        "\n",
        "\n",
        "    print(f\"\\nGenerating hash report...\")\n",
        "    hashes = create_hash_report(test_file, 'hash_report.txt')\n",
        "\n",
        "    print(\"\\n   Generated hashes:\")\n",
        "    for alg, hash_val in hashes.items():\n",
        "        print(f\"   {alg:>6}: {hash_val}\")\n",
        "\n",
        "\n",
        "    print(f\"\\n Creating checksum files...\")\n",
        "    create_all_checksum_files(test_file)\n",
        "\n",
        "\n",
        "    print(f\"\\nInitial (authentic file)\")\n",
        "    initial_results = verify_file_integrity(test_file)\n",
        "    display_verification_summary(initial_results)\n",
        "\n",
        "\n",
        "    print(f\"\\n File tampering simulation...\")\n",
        "    print(\"   Adding malicious content to file...\")\n",
        "\n",
        "    with open(test_file, 'a') as f:\n",
        "        f.write(\"\\n\\n[@321412MKAFSMKFAMSCS()(!(!@()!#@&&^^&**(^%$#$ABDJASJDASJFIJIQUFJF)))]\")\n",
        "\n",
        "    print(f\"   File tampered!\")\n",
        "    print(f\"   New size: {os.path.getsize(test_file)} bytes\")\n",
        "\n",
        "\n",
        "    print(f\"\\n Verification after tampering\")\n",
        "    tampered_results = verify_file_integrity(test_file)\n",
        "    display_verification_summary(tampered_results)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(\"\\nBEFORE TAMPERING:\")\n",
        "    for alg, result in initial_results.items():\n",
        "        status = \" AUTHENTIC\" if result['valid'] else \" FAILED\"\n",
        "        print(f\"  {alg:>6}: {status}\")\n",
        "\n",
        "    print(\"\\nAFTER TAMPERING:\")\n",
        "    for alg, result in tampered_results.items():\n",
        "        status = \" AUTHENTIC\" if result['valid'] else \" TAMPERED\"\n",
        "        print(f\"  {alg:>6}: {status}\")\n",
        "\n",
        "    print(f\"\\nCONCLUSION:\")\n",
        "    print(\"All hash algorithms successfully detected file tampering!\")\n",
        "    print(\"Even minor changes result in completely different hash values.\")\n",
        "\n",
        "    print(f\"\\nGENERATED FILES:\")\n",
        "    print(f\" {test_file} (test file)\")\n",
        "    print(f\" hash_report.txt (comprehensive report)\")\n",
        "    print(f\" {test_file}.md5 (MD5 checksum)\")\n",
        "    print(f\" {test_file}.sha1 (SHA-1 checksum)\")\n",
        "    print(f\" {test_file}.sha256 (SHA-256 checksum)\")\n",
        "    print(f\" {test_file}.sha512 (SHA-512 checksum)\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_experiment()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UP2Nj58cO0cC",
        "outputId": "e4488922-0446-42ae-93b1-971b1bd045e9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HASH FUNCTION FILE INTEGRITY VERIFICATION EXPERIMENT\n",
            "\n",
            " Test file created\n",
            "   File: test_file.txt\n",
            "   Size: 561 bytes\n",
            "\n",
            "Generating hash report...\n",
            "Hash report generated: hash_report.txt\n",
            "\n",
            "   Generated hashes:\n",
            "      MD5: df5624fe6748df2e0b07165222f7a8e4\n",
            "     SHA1: fef2b7bb452ede91488d0cef930c926a8f4c0812\n",
            "   SHA256: d20076ac9f18df4e6e0b0e5b5843e9065db849f277e87f9ed40137d0ee356760\n",
            "   SHA512: 147d922056c874c4c90e8e42c75865f28dc88c29dbcc6d7f4f4181d509b5ad55f8b32808b89fb01c547f94e3aa7848e27335d1d8cea5e68ff0b26f2f8ae1fbf5\n",
            "\n",
            " Creating checksum files...\n",
            "Creating checksum files for: test_file.txt\n",
            "Checksum file created: test_file.txt.md5\n",
            "Checksum file created: test_file.txt.sha1\n",
            "Checksum file created: test_file.txt.sha256\n",
            "Checksum file created: test_file.txt.sha512\n",
            "\n",
            "Initial (authentic file)\n",
            "\n",
            "Verifying integrity of: test_file.txt\n",
            "yes MD5: Checksum OK (Authentic) - MD5\n",
            "yes SHA1: Checksum OK (Authentic) - SHA1\n",
            "yes SHA256: Checksum OK (Authentic) - SHA256\n",
            "yes SHA512: Checksum OK (Authentic) - SHA512\n",
            "\n",
            "Verification Summary:\n",
            "Valid checksums: 4/4\n",
            " FILE INTEGRITY VERIFIED: All checksums match.\n",
            "\n",
            " File tampering simulation...\n",
            "   Adding malicious content to file...\n",
            "   File tampered!\n",
            "   New size: 633 bytes\n",
            "\n",
            " Verification after tampering\n",
            "\n",
            "Verifying integrity of: test_file.txt\n",
            "no MD5: Checksum FAILED (Tampered) - MD5\n",
            "no SHA1: Checksum FAILED (Tampered) - SHA1\n",
            "no SHA256: Checksum FAILED (Tampered) - SHA256\n",
            "no SHA512: Checksum FAILED (Tampered) - SHA512\n",
            "\n",
            "Verification Summary:\n",
            "Valid checksums: 0/4\n",
            " TAMPERING DETECTED: All checksums failed.\n",
            "\n",
            "BEFORE TAMPERING:\n",
            "     MD5:  AUTHENTIC\n",
            "    SHA1:  AUTHENTIC\n",
            "  SHA256:  AUTHENTIC\n",
            "  SHA512:  AUTHENTIC\n",
            "\n",
            "AFTER TAMPERING:\n",
            "     MD5:  TAMPERED\n",
            "    SHA1:  TAMPERED\n",
            "  SHA256:  TAMPERED\n",
            "  SHA512:  TAMPERED\n",
            "\n",
            "CONCLUSION:\n",
            "All hash algorithms successfully detected file tampering!\n",
            "Even minor changes result in completely different hash values.\n",
            "\n",
            "GENERATED FILES:\n",
            " test_file.txt (test file)\n",
            " hash_report.txt (comprehensive report)\n",
            " test_file.txt.md5 (MD5 checksum)\n",
            " test_file.txt.sha1 (SHA-1 checksum)\n",
            " test_file.txt.sha256 (SHA-256 checksum)\n",
            " test_file.txt.sha512 (SHA-512 checksum)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FGd-aPJXQi8a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}